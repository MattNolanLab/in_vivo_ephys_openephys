{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import file_utility\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.toolkit as st\n",
    "import spikeinterface.sorters as sorters\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.widgets as sw\n",
    "import json\n",
    "import pickle\n",
    "import spikeinterfaceHelper\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import settings\n",
    "import logging\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter,filtfilt\n",
    "\n",
    "def filterRecording(recording, sampling_freq, lp_freq=300,hp_freq=6000,order=3):\n",
    "    fn = sampling_freq / 2.\n",
    "    band = np.array([lp_freq, hp_freq]) / fn\n",
    "\n",
    "    b, a = butter(order, band, btype='bandpass')\n",
    "\n",
    "    if not (np.all(np.abs(np.roots(a)) < 1) and np.all(np.abs(np.roots(a)) < 1)):\n",
    "        raise ValueError('Filter is not stable')\n",
    "    \n",
    "    for i in tqdm(range(recording._timeseries.shape[0])):\n",
    "        recording._timeseries[i,:] = filtfilt(b,a,recording._timeseries[i,:])\n",
    "\n",
    "    return recording\n",
    "\n",
    "def plot_waveforms(sorted_df, figure_path):\n",
    "    print('I will plot the waveform shapes for each cluster.')\n",
    "    for cluster in tqdm(range(len(sorted_df))):\n",
    "        #extract waveforms from dataframe\n",
    "        waveforms = sorted_df.waveforms[cluster]\n",
    "        waveforms = np.stack([w for w in waveforms if w is not None])\n",
    "        max_channel = sorted_df.max_channel.values[cluster]\n",
    "        cluster_id = sorted_df.unit_id[cluster]\n",
    "        tetrode = max_channel//settings.num_tetrodes #get the tetrode number\n",
    "        \n",
    "        #plot spike waveform from the same tetrode\n",
    "        fig = plt.figure()\n",
    "        for i in range(4):\n",
    "            ax = fig.add_subplot(2,2,i+1)\n",
    "            ax.plot(waveforms[:,tetrode+i,:].T,color='lightslategray')\n",
    "            template = waveforms[:,tetrode+i,:].mean(0)\n",
    "            ax.plot(template, color='red')\n",
    "            \n",
    "        plt.savefig(figure_path + '/' + sorted_df.session_id[cluster] + '_' + str(cluster_id) + '_waveforms.png', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already there\n"
     ]
    }
   ],
   "source": [
    "sinput = SimpleNamespace()\n",
    "soutput = SimpleNamespace()\n",
    "\n",
    "sinput.recording_to_sort = '/media/data2/pipeline_testing_data/M5_2018-03-06_15-34-44_of'\n",
    "\n",
    "#make output folder\n",
    "try:\n",
    "    os.mkdir(sinput.recording_to_sort+'/processed/')\n",
    "except FileExistsError:\n",
    "    print('Folder already there')\n",
    "    \n",
    "sinput.probe_file =   'sorting_files/tetrode_16.prb'\n",
    "sinput.sort_param = 'sorting_files/params.json'\n",
    "sinput.tetrode_geom = 'sorting_files/geom_all_tetrodes_original.csv'\n",
    "sinput.dead_channel = sinput.recording_to_sort +'/dead_channels.txt'\n",
    "\n",
    "soutput.sorter_df = sinput.recording_to_sort +'/processed/sorted_df.pkl'\n",
    "soutput.sorter_curated_df = sinput.recording_to_sort +'/processed/sorted_curated_df.pkl'\n",
    "\n",
    "soutput.waveform_figure = sinput.recording_to_sort+'/processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n",
      "Loading continuous data...\n"
     ]
    }
   ],
   "source": [
    "signal = file_utility.load_OpenEphysRecording(sinput.recording_to_sort)\n",
    "geom = pd.read_csv(sinput.tetrode_geom, header=None).values\n",
    "bad_channel = file_utility.getDeadChannel(sinput.dead_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating extractor and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spikeextractors.extractors.numpyextractors.numpyextractors.NumpyRecordingExtractor at 0x7f70d1413c90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording = se.NumpyRecordingExtractor(signal,settings.sampling_rate,geom)\n",
    "recording = recording.load_probe_file(sinput.probe_file) #load probe definition\n",
    "filterRecording(recording,settings.sampling_rate) #filer recording\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = st.preprocessing.remove_bad_channels(recording, bad_channel_ids=bad_channel) #remove bad channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 workers.\n",
      "Using tmpdir: /tmp/tmp6tovl658\n",
      "Num. workers = 2\n",
      "Preparing /tmp/tmp6tovl658/timeseries.hdf5...\n",
      "Preparing neighborhood sorters (M=15, N=57851904)...\n",
      "Neighboorhood of channel 0 has 15 channels.\n",
      "Neighboorhood of channel 2 has 15 channels.\n",
      "Detecting events on channel 1 (phase1)...\n",
      "Detecting events on channel 3 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:20.761078\n",
      "Num events detected on channel 1 (phase1): 89243\n",
      "Computing PCA features for channel 1 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:20.902034\n",
      "Num events detected on channel 3 (phase1): 101180\n",
      "Computing PCA features for channel 3 (phase1)...\n",
      "Clustering for channel 3 (phase1)...\n",
      "Clustering for channel 1 (phase1)...\n",
      "Found 1 clusters for channel 1 (phase1)...\n",
      "Computing templates for channel 1 (phase1)...\n",
      "Found 1 clusters for channel 3 (phase1)...\n",
      "Computing templates for channel 3 (phase1)...\n",
      "Re-assigning events for channel 1 (phase1)...\n",
      "Re-assigning events for channel 3 (phase1)...\n",
      "Neighboorhood of channel 3 has 15 channels.\n",
      "Neighboorhood of channel 1 has 15 channels.\n",
      "Detecting events on channel 4 (phase1)...\n",
      "Detecting events on channel 2 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:22.075196\n",
      "Elapsed time for detect on neighborhood: 0:00:22.074634\n",
      "Num events detected on channel 2 (phase1): 58868\n",
      "Num events detected on channel 4 (phase1): 219984\n",
      "Computing PCA features for channel 2 (phase1)...\n",
      "Computing PCA features for channel 4 (phase1)...\n",
      "Clustering for channel 4 (phase1)...\n",
      "Clustering for channel 2 (phase1)...\n",
      "Found 1 clusters for channel 2 (phase1)...\n",
      "Computing templates for channel 2 (phase1)...\n",
      "Found 3 clusters for channel 4 (phase1)...\n",
      "Computing templates for channel 4 (phase1)...\n",
      "Re-assigning events for channel 2 (phase1)...\n",
      "Neighboorhood of channel 4 has 15 channels.\n",
      "Detecting events on channel 5 (phase1)...\n",
      "Re-assigning events for channel 4 (phase1)...\n",
      "Neighboorhood of channel 6 has 15 channels.\n",
      "Detecting events on channel 7 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:22.877691\n",
      "Num events detected on channel 5 (phase1): 254236\n",
      "Computing PCA features for channel 5 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:22.811252\n",
      "Num events detected on channel 7 (phase1): 250336\n",
      "Computing PCA features for channel 7 (phase1)...\n",
      "Clustering for channel 5 (phase1)...\n",
      "Found 4 clusters for channel 5 (phase1)...\n",
      "Computing templates for channel 5 (phase1)...\n",
      "Clustering for channel 7 (phase1)...\n",
      "Found 2 clusters for channel 7 (phase1)...\n",
      "Computing templates for channel 7 (phase1)...\n",
      "Re-assigning events for channel 5 (phase1)...\n",
      "Re-assigning 27 events from 5 to 4 with dt=4 (k=2)\n",
      "Neighboorhood of channel 5 has 15 channels.\n",
      "Detecting events on channel 6 (phase1)...\n",
      "Re-assigning events for channel 7 (phase1)...\n",
      "Neighboorhood of channel 7 has 15 channels.\n",
      "Detecting events on channel 8 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:21.250463\n",
      "Num events detected on channel 6 (phase1): 210262\n",
      "Computing PCA features for channel 6 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:22.155626\n",
      "Num events detected on channel 8 (phase1): 72365\n",
      "Computing PCA features for channel 8 (phase1)...\n",
      "Clustering for channel 6 (phase1)...\n",
      "Found 3 clusters for channel 6 (phase1)...\n",
      "Computing templates for channel 6 (phase1)...\n",
      "Clustering for channel 8 (phase1)...\n",
      "Found 1 clusters for channel 8 (phase1)...\n",
      "Computing templates for channel 8 (phase1)...\n",
      "Re-assigning events for channel 8 (phase1)...\n",
      "Re-assigning events for channel 6 (phase1)...\n",
      "Neighboorhood of channel 10 has 15 channels.\n",
      "Neighboorhood of channel 8 has 15 channels.\n",
      "Detecting events on channel 9 (phase1)...\n",
      "Detecting events on channel 11 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:23.146192\n",
      "Elapsed time for detect on neighborhood: 0:00:23.155971\n",
      "Num events detected on channel 9 (phase1): 80354\n",
      "Num events detected on channel 11 (phase1): 96677\n",
      "Computing PCA features for channel 9 (phase1)...\n",
      "Computing PCA features for channel 11 (phase1)...\n",
      "Clustering for channel 9 (phase1)...\n",
      "Clustering for channel 11 (phase1)...\n",
      "Found 1 clusters for channel 9 (phase1)...\n",
      "Computing templates for channel 9 (phase1)...\n",
      "Found 2 clusters for channel 11 (phase1)...\n",
      "Computing templates for channel 11 (phase1)...\n",
      "Re-assigning events for channel 11 (phase1)...\n",
      "Re-assigning events for channel 9 (phase1)...\n",
      "Neighboorhood of channel 11 has 15 channels.\n",
      "Neighboorhood of channel 9 has 15 channels.\n",
      "Detecting events on channel 10 (phase1)...\n",
      "Detecting events on channel 12 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:27.343306\n",
      "Elapsed time for detect on neighborhood: 0:00:27.340078\n",
      "Num events detected on channel 10 (phase1): 77874\n",
      "Computing PCA features for channel 10 (phase1)...\n",
      "Num events detected on channel 12 (phase1): 46092\n",
      "Computing PCA features for channel 12 (phase1)...\n",
      "Clustering for channel 10 (phase1)...\n",
      "Clustering for channel 12 (phase1)...\n",
      "Found 1 clusters for channel 12 (phase1)...\n",
      "Computing templates for channel 12 (phase1)...\n",
      "Found 2 clusters for channel 10 (phase1)...\n",
      "Computing templates for channel 10 (phase1)...\n",
      "Re-assigning events for channel 12 (phase1)...\n",
      "Re-assigning events for channel 10 (phase1)...\n",
      "Neighboorhood of channel 14 has 15 channels.\n",
      "Neighboorhood of channel 12 has 15 channels.\n",
      "Detecting events on channel 13 (phase1)...\n",
      "Detecting events on channel 15 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:23.123019\n",
      "Elapsed time for detect on neighborhood: 0:00:23.125274\n",
      "Num events detected on channel 15 (phase1): 50852\n",
      "Num events detected on channel 13 (phase1): 58843\n",
      "Computing PCA features for channel 15 (phase1)...\n",
      "Computing PCA features for channel 13 (phase1)...\n",
      "Clustering for channel 13 (phase1)...\n",
      "Clustering for channel 15 (phase1)...\n",
      "Found 1 clusters for channel 15 (phase1)...\n",
      "Computing templates for channel 15 (phase1)...\n",
      "Found 1 clusters for channel 13 (phase1)...\n",
      "Computing templates for channel 13 (phase1)...\n",
      "Re-assigning events for channel 15 (phase1)...\n",
      "Re-assigning events for channel 13 (phase1)...\n",
      "Neighboorhood of channel 13 has 15 channels.\n",
      "Detecting events on channel 14 (phase1)...\n",
      "Elapsed time for detect on neighborhood: 0:00:14.478172\n",
      "Num events detected on channel 14 (phase1): 59645\n",
      "Computing PCA features for channel 14 (phase1)...\n",
      "Clustering for channel 14 (phase1)...\n",
      "Found 1 clusters for channel 14 (phase1)...\n",
      "Computing templates for channel 14 (phase1)...\n",
      "Re-assigning events for channel 14 (phase1)...\n",
      "Neighboorhood of channel 2 has 15 channels.\n",
      "Neighboorhood of channel 0 has 15 channels.\n",
      "Computing PCA features for channel 1 (phase2)...\n",
      "Computing PCA features for channel 3 (phase2)...\n",
      "No duplicate events found for channel 0 in phase2\n",
      "No duplicate events found for channel 2 in phase2\n",
      "Clustering for channel 3 (phase2)...\n",
      "Clustering for channel 1 (phase2)...\n",
      "Found 1 clusters for channel 1 (phase2)...\n",
      "Neighboorhood of channel 1 has 15 channels.\n",
      "Computing PCA features for channel 2 (phase2)...\n",
      "No duplicate events found for channel 1 in phase2\n",
      "Found 1 clusters for channel 3 (phase2)...\n",
      "Neighboorhood of channel 3 has 15 channels.\n",
      "Computing PCA features for channel 4 (phase2)...\n",
      "No duplicate events found for channel 3 in phase2\n",
      "Clustering for channel 4 (phase2)...\n",
      "Clustering for channel 2 (phase2)...\n",
      "Found 1 clusters for channel 2 (phase2)...\n",
      "Neighboorhood of channel 4 has 15 channels.\n",
      "Computing PCA features for channel 5 (phase2)...\n",
      "No duplicate events found for channel 4 in phase2\n",
      "Found 3 clusters for channel 4 (phase2)...\n",
      "Neighboorhood of channel 6 has 15 channels.\n",
      "Computing PCA features for channel 7 (phase2)...\n",
      "No duplicate events found for channel 6 in phase2\n",
      "Clustering for channel 7 (phase2)...\n",
      "Clustering for channel 5 (phase2)...\n",
      "Found 1 clusters for channel 7 (phase2)...\n",
      "Neighboorhood of channel 7 has 15 channels.\n",
      "Computing PCA features for channel 8 (phase2)...\n",
      "No duplicate events found for channel 7 in phase2\n",
      "Found 2 clusters for channel 5 (phase2)...\n",
      "Neighboorhood of channel 5 has 15 channels.\n",
      "Computing PCA features for channel 6 (phase2)...\n",
      "No duplicate events found for channel 5 in phase2\n",
      "Clustering for channel 6 (phase2)...\n",
      "Clustering for channel 8 (phase2)...\n",
      "Found 1 clusters for channel 8 (phase2)...\n",
      "Neighboorhood of channel 8 has 15 channels.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PCA features for channel 9 (phase2)...\n",
      "No duplicate events found for channel 8 in phase2\n",
      "Found 2 clusters for channel 6 (phase2)...\n",
      "Neighboorhood of channel 10 has 15 channels.\n",
      "Computing PCA features for channel 11 (phase2)...\n",
      "No duplicate events found for channel 10 in phase2\n",
      "Clustering for channel 9 (phase2)...\n",
      "Clustering for channel 11 (phase2)...\n",
      "Found 1 clusters for channel 9 (phase2)...\n",
      "Neighboorhood of channel 9 has 15 channels.\n",
      "Computing PCA features for channel 10 (phase2)...\n",
      "No duplicate events found for channel 9 in phase2\n",
      "Found 2 clusters for channel 11 (phase2)...\n",
      "Neighboorhood of channel 11 has 15 channels.\n",
      "Computing PCA features for channel 12 (phase2)...\n",
      "No duplicate events found for channel 11 in phase2\n",
      "Clustering for channel 10 (phase2)...\n",
      "Clustering for channel 12 (phase2)...\n",
      "Found 1 clusters for channel 12 (phase2)...\n",
      "Neighboorhood of channel 12 has 15 channels.\n",
      "Computing PCA features for channel 13 (phase2)...\n",
      "No duplicate events found for channel 12 in phase2\n",
      "Found 2 clusters for channel 10 (phase2)...\n",
      "Neighboorhood of channel 14 has 15 channels.\n",
      "Computing PCA features for channel 15 (phase2)...\n",
      "No duplicate events found for channel 14 in phase2\n",
      "Clustering for channel 15 (phase2)...\n",
      "Clustering for channel 13 (phase2)...\n",
      "Found 1 clusters for channel 15 (phase2)...\n",
      "Found 1 clusters for channel 13 (phase2)...\n",
      "Neighboorhood of channel 13 has 15 channels.\n",
      "Computing PCA features for channel 14 (phase2)...\n",
      "No duplicate events found for channel 13 in phase2\n",
      "Clustering for channel 14 (phase2)...\n",
      "Found 1 clusters for channel 14 (phase2)...\n",
      "Preparing output...\n",
      "Done with ms4alg.\n",
      "Cleaning tmpdir::::: /tmp/tmp6tovl658\n",
      "mountainsort4 run time 608.10s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'types.SimpleNamespace' object has no attribute 'sorter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-24ab717626d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     adjacency_radius=param['adjacency_radius'], detect_sign=param['detect_sign'],verbose=True)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorting_ms4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'types.SimpleNamespace' object has no attribute 'sorter'"
     ]
    }
   ],
   "source": [
    "with open(sinput.sort_param) as f:\n",
    "    param = json.load(f)\n",
    "sorting_ms4 = sorters.run_sorter(settings.sorterName,recording, output_folder=settings.sorterName,\n",
    "    adjacency_radius=param['adjacency_radius'], detect_sign=param['detect_sign'],verbose=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some sorting metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.postprocessing.get_unit_max_channels(recording, sorting_ms4, max_spikes_per_unit=100)\n",
    "st.postprocessing.get_unit_waveforms(recording, sorting_ms4, max_spikes_per_unit=100)\n",
    "\n",
    "for id in sorting_ms4.get_unit_ids():\n",
    "    number_of_spikes = len(sorting_ms4.get_unit_spike_train(id))\n",
    "    mean_firing_rate = number_of_spikes/(recording._recording._timeseries.shape[1]/settings.sampling_rate)\n",
    "    sorting_ms4.set_unit_property(id,'number_of_spikes',number_of_spikes)\n",
    "    sorting_ms4.set_unit_property(id, 'mean_firing_rate', mean_firing_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save sorted result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = sinput.recording_to_sort.split('/')[-1]\n",
    "sorter_df=spikeinterfaceHelper.sorter2dataframe(sorting_ms4,session_id)\n",
    "sorter_df.to_pickle(soutput.sorter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curate sortings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21]\n",
      "[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21]\n",
      "[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "sorting_ms4_curated = st.curation.threshold_snr(sorting=sorting_ms4, recording = recording,\n",
    "  threshold =2, threshold_sign='less', max_snr_spikes_per_unit=100, apply_filter=False) #remove when less than threshold\n",
    "print(sorting_ms4_curated.get_unit_ids())\n",
    "\n",
    "sorting_ms4_curated=st.curation.threshold_firing_rate(sorting_ms4_curated,\n",
    "    threshold=0.5, threshold_sign='less')\n",
    "print(sorting_ms4_curated.get_unit_ids())\n",
    "\n",
    "sorting_ms4_curated=st.curation.threshold_isi_violations(sorting_ms4_curated, threshold = 0.9)\n",
    "print(sorting_ms4_curated.get_unit_ids())\n",
    "\n",
    "sorting_ms4_curated = st.curation.threshold_firing_rate(sorting=sorting_ms4_curated,threshold=0.5,threshold_sign='less')\n",
    "print(sorting_ms4_curated.get_unit_ids())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save curated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save curated data\n",
    "curated_sorter_df = spikeinterfaceHelper.sorter2dataframe(sorting_ms4_curated, session_id)\n",
    "curated_sorter_df.to_pickle(soutput.sorter_curated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot spike waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will plot the waveform shapes for each cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:16<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "plot_waveforms(curated_sorter_df, soutput.waveform_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
